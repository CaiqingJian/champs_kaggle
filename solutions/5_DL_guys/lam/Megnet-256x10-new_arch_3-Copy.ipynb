{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:09.076360Z",
     "start_time": "2019-08-25T08:30:09.062844Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:11.267671Z",
     "start_time": "2019-08-25T08:30:09.078187Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "from tqdm.autonotebook import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU, GRU\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:11.291314Z",
     "start_time": "2019-08-25T08:30:11.269817Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:11.313959Z",
     "start_time": "2019-08-25T08:30:11.293262Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:11.336098Z",
     "start_time": "2019-08-25T08:30:11.315303Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:11.362775Z",
     "start_time": "2019-08-25T08:30:11.337574Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_champs import constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:16.335618Z",
     "start_time": "2019-08-25T08:30:11.364442Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:16.368077Z",
     "start_time": "2019-08-25T08:30:16.338325Z"
    }
   },
   "outputs": [],
   "source": [
    "y_mean = train.scalar_coupling_constant.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:16.405298Z",
     "start_time": "2019-08-25T08:30:16.370516Z"
    }
   },
   "outputs": [],
   "source": [
    "y_std = train.scalar_coupling_constant.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:17.387333Z",
     "start_time": "2019-08-25T08:30:16.406936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "1JHC    2.548219\n",
       "1JHN    2.275415\n",
       "2JHC    0.999041\n",
       "2JHH    0.983063\n",
       "2JHN    1.086673\n",
       "3JHC    0.911788\n",
       "3JHH    1.122420\n",
       "3JHN   -0.033818\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log((train.scalar_coupling_constant - train.type.map(train.groupby('type').scalar_coupling_constant.mean())).abs().groupby(train.type).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:17.559320Z",
     "start_time": "2019-08-25T08:30:17.388931Z"
    }
   },
   "outputs": [],
   "source": [
    "molecules = train.molecule_name.drop_duplicates().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:17.586588Z",
     "start_time": "2019-08-25T08:30:17.560899Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ind, valid_ind = train_test_split(np.arange(len(molecules)),\n",
    "                                        test_size=5000,\n",
    "                                        random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:17.624826Z",
     "start_time": "2019-08-25T08:30:17.588020Z"
    }
   },
   "outputs": [],
   "source": [
    "assert not set(train_ind).intersection(valid_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:17.649022Z",
     "start_time": "2019-08-25T08:30:17.626343Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80003, 5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ind), len(valid_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train valid subet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:17.672796Z",
     "start_time": "2019-08-25T08:30:17.650385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19669 26783  1698 47278 33476 59113 40999 64242 25723 71229]\n",
      "[55624 62327 36561 67391 19447 20288 70596 59541 32479 52121]\n"
     ]
    }
   ],
   "source": [
    "# Check reproducibility\n",
    "rs = np.random.RandomState(seed=1234)\n",
    "print(rs.choice(train_ind, 10))\n",
    "print(rs.choice(valid_ind, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.317054Z",
     "start_time": "2019-08-25T08:30:17.674233Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train.loc[train.molecule_name.isin(molecules.iloc[train_ind])]\n",
    "val_data = train.loc[train.molecule_name.isin(molecules.iloc[valid_ind])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.372367Z",
     "start_time": "2019-08-25T08:30:18.318688Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from kaggle_champs.dataset import ChampsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.398939Z",
     "start_time": "2019-08-25T08:30:18.374112Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import openbabel\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.autonotebook import tqdm\n",
    "from kaggle_champs.dataset import mol_to_data_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.497219Z",
     "start_time": "2019-08-25T08:30:18.400955Z"
    }
   },
   "outputs": [],
   "source": [
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, metadata=None, base_dir=None, transform=None):\n",
    "        self.molecules = metadata.molecule_name.unique()\n",
    "        self.metadata = dict([\n",
    "            (ind, df) for ind, df in tqdm(metadata.groupby('molecule_name'))\n",
    "        ])\n",
    "        self.base_dir = base_dir\n",
    "        self.transform = transform\n",
    "        self.conversion = openbabel.OBConversion()\n",
    "        self.conversion.SetInAndOutFormats(\"xyz\", \"mdl\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        mol = openbabel.OBMol()\n",
    "        mol_name = self.molecules[index]\n",
    "\n",
    "        xyz_file = os.path.join(self.base_dir, f'{mol_name}.xyz')\n",
    "        if not os.path.exists(xyz_file):\n",
    "            raise FileNotFoundError(f'Expecting file {xyz_file} not found')\n",
    "        self.conversion.ReadFile(mol, xyz_file)\n",
    "\n",
    "        data = mol_to_data_v2(mol)\n",
    "        data.mol_ind = torch.tensor([[index]], dtype=torch.long)\n",
    "        \n",
    "        data = self._add_targets(data, metadata=self.metadata[mol_name])\n",
    "        \n",
    "        data.graph = nx.Graph()\n",
    "        data.graph.add_edges_from(data.edge_index.transpose(1,0).cpu().numpy())\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "            \n",
    "        if hasattr(data, 'graph'):\n",
    "            del data.graph\n",
    "        return data\n",
    "    \n",
    "    def _add_inverse_couple(self, couples):\n",
    "        inverse_direction = couples.rename(\n",
    "            {'atom_index_1': 'atom_index_0', \n",
    "             'atom_index_0': 'atom_index_1'}, \n",
    "            axis=1)\n",
    "        \n",
    "        couples = couples.append(\n",
    "            inverse_direction,\n",
    "            sort=False\n",
    "        )\n",
    "        couples = couples.sort_values(['atom_index_0',\n",
    "                                       'atom_index_1'])\n",
    "        \n",
    "        return couples\n",
    "    \n",
    "    def _add_y(self, data, couples):\n",
    "        if 'scalar_coupling_constant' in couples.columns:\n",
    "            data.y = torch.tensor(\n",
    "                couples['scalar_coupling_constant'].values,\n",
    "                dtype=torch.float).view(-1,1)\n",
    "        else:\n",
    "            data.y = torch.zeros((len(couples), 1), dtype=torch.float)\n",
    "        return data\n",
    "    \n",
    "    def _add_targets(self, data, metadata):\n",
    "        couples = metadata.copy()        \n",
    "        couples = self._add_inverse_couple(couples)\n",
    "        \n",
    "        \n",
    "        data.couples_ind = torch.tensor(\n",
    "            couples[['atom_index_0',\n",
    "                     'atom_index_1']].values,\n",
    "            dtype=torch.long)\n",
    "        \n",
    "        data = self._add_y(data, couples)\n",
    "        \n",
    "        data.type = torch.tensor(\n",
    "            couples['type'].map(constants.TYPES_DICT).values,\n",
    "            dtype=torch.long)\n",
    "        \n",
    "        data.sample_weight = torch.tensor(\n",
    "            couples['type'].map(constants.TYPES_WEIGHTS).values,\n",
    "            dtype=torch.float)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.523534Z",
     "start_time": "2019-08-25T08:30:18.498724Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from kaggle_champs.preprocessing import RandomRotation, AddVirtualEdges, AddEdgeDistanceAndDirection, SortTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.548886Z",
     "start_time": "2019-08-25T08:30:18.525251Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.578629Z",
     "start_time": "2019-08-25T08:30:18.550706Z"
    }
   },
   "outputs": [],
   "source": [
    "class AddEdgeDistanceAndDirection:\n",
    "    def __init__(self, dist_noise=0., gauss_base_max=4, gauss_base_steps=20, keep=True):\n",
    "        self.dist_noise = dist_noise\n",
    "        self.gauss_base_max = gauss_base_max\n",
    "        self.gauss_base_steps = gauss_base_steps\n",
    "        self.keep = True\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        (row, col), pos, edge_attr = data.edge_index, data.pos, data.edge_attr\n",
    "\n",
    "        dist = torch.norm(pos[col] - pos[row], p=2, dim=-1).view(-1, 1)\n",
    "        \n",
    "        if self.dist_noise > 0:\n",
    "            noise = 1 + torch.randn_like(dist, dtype=dist.dtype) * self.dist_noise\n",
    "            dist = dist * noise\n",
    "\n",
    "        direction = (pos[col] - pos[row]) / dist\n",
    "        if self.keep:\n",
    "            data.dist = dist\n",
    "            data.direction = direction\n",
    "        \n",
    "        base = torch.linspace(self.gauss_base_max/self.gauss_base_steps,\n",
    "                              self.gauss_base_max, \n",
    "                              self.gauss_base_steps, \n",
    "                              dtype=torch.float).view(1, -1)    # shape 1xn for broadcasting\n",
    "        \n",
    "        dist = torch.exp(-(dist - base) ** 2 / 0.5 ** 2)\n",
    "        \n",
    "        edge_attr = edge_attr.view(-1, 1) if edge_attr.dim() == 1 else edge_attr\n",
    "        data.edge_attr = torch.cat(\n",
    "                [edge_attr,\n",
    "                 dist.type_as(edge_attr),\n",
    "                 direction.type_as(edge_attr)],\n",
    "                dim=-1)      \n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.605927Z",
     "start_time": "2019-08-25T08:30:18.582342Z"
    }
   },
   "outputs": [],
   "source": [
    "class AddBondLinks:\n",
    "    def __call__(self, data):\n",
    "        bonds_ind = data.bonds_edge_ind\n",
    "        \n",
    "        bonds_from = bonds_ind.view(-1, 1).repeat(1, (len(bonds_ind))).view(-1)\n",
    "        bonds_to = bonds_ind.view(-1).repeat(1, len(data.bonds_edge_ind)).view(-1)\n",
    "        bonds_links = torch.stack([bonds_from, bonds_to], dim=1)  # all couples, will filter\n",
    "        \n",
    "        filter_correct_common_node = (data.edge_index[:, bonds_from][1] == data.edge_index[:, bonds_to][0])\n",
    "        filter_remove_self_loop = (data.edge_index[:, bonds_from][0] != data.edge_index[:, bonds_to][1])\n",
    "        \n",
    "        data.bonds_links_edge_ind = bonds_links[filter_correct_common_node * filter_remove_self_loop]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.630316Z",
     "start_time": "2019-08-25T08:30:18.608184Z"
    }
   },
   "outputs": [],
   "source": [
    "class AddCounts:\n",
    "    def __call__(self, data):\n",
    "        data.count_nodes = torch.tensor([[data.num_nodes]], dtype=torch.long)\n",
    "        data.count_edges = torch.tensor([[data.num_edges]], dtype=torch.long)\n",
    "        data.count_couples = torch.tensor([[data.couples_ind.size(0)]], dtype=torch.long)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.652952Z",
     "start_time": "2019-08-25T08:30:18.631714Z"
    }
   },
   "outputs": [],
   "source": [
    "class AddGlobalAttr:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, data):\n",
    "        data.global_attr = torch.zeros((1, 1), dtype=torch.float)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.681170Z",
     "start_time": "2019-08-25T08:30:18.654355Z"
    }
   },
   "outputs": [],
   "source": [
    "class SortTarget:\n",
    "    def _get_index(self, data, row, col):\n",
    "        idx = row * (data.num_nodes-1) + col\n",
    "        idx[row < col] = idx[row < col] - 1\n",
    "        return idx\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        target = torch.zeros((data.num_edges, data.y.size()[1]), dtype=torch.float)        \n",
    "        weights = torch.zeros((data.num_edges), dtype=torch.float)        \n",
    "        mask = torch.zeros((data.num_edges), dtype=torch.bool)      \n",
    "        types = torch.zeros((data.num_edges), dtype=torch.long)\n",
    "        \n",
    "        row, col = data.couples_ind.transpose(1,0)\n",
    "        indexes = self._get_index(data, row, col)\n",
    "        \n",
    "        mask[indexes] = True\n",
    "        weights[indexes] = data.sample_weight\n",
    "        target[indexes] = data.y\n",
    "        types[indexes] = data.type\n",
    "        \n",
    "        #data.mask = mask\n",
    "        data.y = target[mask]\n",
    "        data.sample_weight = weights[mask]\n",
    "        data.type = types[mask]\n",
    "        \n",
    "        assert torch.equal(data.couples_ind, data.edge_index[:, mask].transpose(1,0))\n",
    "        data.couples_edge_ind = torch.arange(data.num_edges, dtype=torch.long)[mask].view(-1,1)\n",
    "        return data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.709151Z",
     "start_time": "2019-08-25T08:30:18.682625Z"
    }
   },
   "outputs": [],
   "source": [
    "class AddBondPath:\n",
    "    def __call__(self, data):\n",
    "        # suffix _index to get node index adjustment\n",
    "        data.paths_index = self.find_paths(data).transpose(1,0)  \n",
    "        data.paths_edge_ind = torch.cat(\n",
    "            [self._nodes_to_edge_ind(data, data.paths_index[i], data.paths_index[i+1]) for i in range(3)], \n",
    "            dim=1)\n",
    "        return data\n",
    "    \n",
    "    def _nodes_to_edge_ind(self, data, node_from, node_to):\n",
    "        edge_ind = node_from * (data.num_nodes-1) + node_to\n",
    "        edge_ind[node_from < node_to] = edge_ind[node_from < node_to] - 1\n",
    "        return edge_ind.view(-1, 1)\n",
    "    \n",
    "    def find_paths(self, data):\n",
    "        assert hasattr(data, 'couples_ind')\n",
    "        assert hasattr(data, 'graph')\n",
    "\n",
    "        all_paths = nx.shortest_path(data.graph)\n",
    "        paths = []\n",
    "        for (from_, to_) in data.couples_ind.numpy():\n",
    "            path = torch.tensor(all_paths[from_][to_], dtype=torch.long).view(-1,1)\n",
    "            paths.append(path)\n",
    "\n",
    "        paths = torch.nn.utils.rnn.pad_sequence(paths, batch_first=True).squeeze()\n",
    "        if paths.size(1) < 4:\n",
    "            paths = torch.nn.functional.pad(paths, (0, 4 - paths.size(1)))\n",
    "        return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.734837Z",
     "start_time": "2019-08-25T08:30:18.710571Z"
    }
   },
   "outputs": [],
   "source": [
    "class AddInverseCouples:\n",
    "    def find_inverse_couple_position(self, node_from, node_to):\n",
    "        df = pd.DataFrame({\n",
    "            'from': node_from,\n",
    "            'to': node_to,\n",
    "        }).reset_index()\n",
    "        inverse = df.rename({\n",
    "            'from': 'to',\n",
    "            'to': 'from',\n",
    "        },axis=1)\n",
    "        merged = pd.merge(df, inverse, on=['from', 'to'], suffixes=('', '_inverse'))\n",
    "        assert merged.shape[0] == df.shape[0]\n",
    "        return merged.sort_values('index').index_inverse.values\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        assert hasattr(data, 'couples_ind')\n",
    "        node_from, node_to = data.couples_ind[:,0].numpy(), data.couples_ind[:,1].numpy()\n",
    "        data.inverse_couple_ind = torch.tensor(self.find_inverse_couple_position(node_from, node_to), dtype=torch.long)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.758847Z",
     "start_time": "2019-08-25T08:30:18.736239Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_inverse_couple_position(self, node_from, node_to):\n",
    "    df = pd.DataFrame({\n",
    "        'from': node_from,\n",
    "        'to': node_to,\n",
    "    }).reset_index()\n",
    "    inverse = df.rename({\n",
    "        'from': 'to',\n",
    "        'to': 'from',\n",
    "    },axis=1)\n",
    "    merged = pd.merge(df, inverse, left_on=['from', 'to'], right_on=['to', 'from'], suffixes=('', '_inverse'))\n",
    "    assert merged.shape[0] == df.shape[0]\n",
    "    return merged.sort_values('index').index_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.783885Z",
     "start_time": "2019-08-25T08:30:18.760259Z"
    }
   },
   "outputs": [],
   "source": [
    "def correct_batch_edge_ind(batch):\n",
    "    offset_edge_ind = torch.zeros_like(batch.count_edges)\n",
    "    offset_edge_ind[1:] = batch.count_edges[:-1].cumsum(dim=0)\n",
    "    for k in ['bonds_edge_ind', 'bonds_links_edge_ind', 'paths_edge_ind', 'couples_edge_ind']:\n",
    "        if hasattr(batch, k):\n",
    "            batch[k] = batch[k] + offset_edge_ind[batch[k+'_batch']]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:18.812430Z",
     "start_time": "2019-08-25T08:30:18.785570Z"
    }
   },
   "outputs": [],
   "source": [
    "def correct_inverse_couples_ind(batch):\n",
    "    offset = torch.zeros_like(batch.count_couples)\n",
    "    offset[1:] = batch.count_couples[:-1].cumsum(dim=0)\n",
    "    batch.inverse_couple_ind = batch.inverse_couple_ind + offset[batch.inverse_couple_ind_batch].view(-1)\n",
    "    assert torch.equal(batch.couples_edge_ind[batch.inverse_couple_ind][batch.inverse_couple_ind],\n",
    "                       batch.couples_edge_ind)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.295484Z",
     "start_time": "2019-08-25T08:30:18.814180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ee61cef2f944069934c8763cd334c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80003), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2cc886a32c491f8bd9b7b80997c3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MoleculeDataset(metadata=train_data,\n",
    "                                base_dir='/home/ubuntu/datalab/data/structures_xyz/',\n",
    "                                transform=T.Compose([\n",
    "                                    AddBondPath(),\n",
    "                                    AddVirtualEdges(),\n",
    "                                    RandomRotation(),\n",
    "                                    AddEdgeDistanceAndDirection(dist_noise=0.),\n",
    "                                    AddGlobalAttr(),\n",
    "                                    SortTarget(),\n",
    "                                    AddBondLinks(),\n",
    "                                    AddCounts(),\n",
    "                                    AddInverseCouples(),\n",
    "                                ]))\n",
    "\n",
    "val_dataset = MoleculeDataset(metadata=val_data,\n",
    "                                base_dir='/home/ubuntu/datalab/data/structures_xyz/',\n",
    "                              transform=T.Compose([\n",
    "                                  AddBondPath(),\n",
    "                                  AddVirtualEdges(),\n",
    "                                  AddEdgeDistanceAndDirection(dist_noise=0.),\n",
    "                                  AddGlobalAttr(),\n",
    "                                  SortTarget(),\n",
    "                                  AddBondLinks(),\n",
    "                                  AddCounts(),\n",
    "                                  AddInverseCouples(),\n",
    "                              ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.364314Z",
     "start_time": "2019-08-25T08:30:43.297135Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FP16_Data(bonds_edge_ind=[20, 1], bonds_links_edge_ind=[36, 2], count_couples=[1, 1], count_edges=[1, 1], count_nodes=[1, 1], couples_edge_ind=[86, 1], couples_ind=[86, 2], direction=[110, 3], dist=[110, 1], edge_attr=[110, 34], edge_index=[2, 110], global_attr=[1, 1], inverse_couple_ind=[86], mol_ind=[1, 1], paths_edge_ind=[86, 3], paths_index=[4, 86], pos=[11, 3], sample_weight=[86], type=[86], x=[11, 28], y=[86, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train_dataset[10]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.391129Z",
     "start_time": "2019-08-25T08:30:43.365938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(data.inverse_couple_ind[data.inverse_couple_ind], torch.arange(86))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.418166Z",
     "start_time": "2019-08-25T08:30:43.392768Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_champs.modelling import MegNetBlock, create_mlp_v2, MegNetBlock_v2, MegNetBlock_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.443569Z",
     "start_time": "2019-08-25T08:30:43.419868Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.468781Z",
     "start_time": "2019-08-25T08:30:43.445142Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.500514Z",
     "start_time": "2019-08-25T08:30:43.470445Z"
    }
   },
   "outputs": [],
   "source": [
    "def gather_embedding(data, x_out, edge_out, u_out, couple_type):\n",
    "    n_bonds = int(couple_type[0])\n",
    "    couple_filter = (data.type == constants.TYPES_DICT[couple_type])\n",
    "    couples_edge_ind = data.couples_edge_ind.view(-1)\n",
    "    \n",
    "    merged = [\n",
    "        u_out[data.batch[data.edge_index[0][couples_edge_ind][couple_filter]]],\n",
    "    ]\n",
    "    if n_bonds > 1:\n",
    "        merged.append(edge_out[couples_edge_ind][couple_filter])\n",
    "        \n",
    "    node_ind = data.paths_index.transpose(1,0)[:, :n_bonds+1][couple_filter] # convert_node_ind(data, 'paths')[:, :n_bonds+1]\n",
    "    for i in range(n_bonds+1):\n",
    "        merged.append(x_out[node_ind[:,i]])\n",
    "        \n",
    "    for i in range(n_bonds):\n",
    "        edge_ind = data.paths_edge_ind[:,i] # convert_couple_to_edge_ind(data, data.paths_index[i], data.paths_index[i+1], data.paths_edge_ind_batch)\n",
    "        merged.append(edge_out[edge_ind[couple_filter]])\n",
    "    return torch.cat(merged, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.532164Z",
     "start_time": "2019-08-25T08:30:43.502055Z"
    }
   },
   "outputs": [],
   "source": [
    "class OutputLayer_new(torch.nn.Module):\n",
    "    def __init__(self, rep_dim, dim, y_mean, y_std, couple_type):\n",
    "        super(OutputLayer_new, self).__init__()\n",
    "        self.scaling = torch.nn.Linear(1, 1)\n",
    "        self.scaling.bias = torch.nn.Parameter(torch.tensor(y_mean,\n",
    "                                                            dtype=torch.float),\n",
    "                                               requires_grad=False)\n",
    "        self.scaling.weight = torch.nn.Parameter(torch.tensor(\n",
    "            [[y_std]], dtype=torch.float),\n",
    "                                                 requires_grad=False)\n",
    "        self.couple_type = couple_type\n",
    "        n_bonds = int(couple_type[0])\n",
    "        \n",
    "        if n_bonds == 1:\n",
    "            input_dim = dim * (n_bonds + (n_bonds + 1) + 1)  # edges + nodes + u\n",
    "        else:\n",
    "            input_dim = dim * (n_bonds + (n_bonds + 1) + 2)  # edges + nodes + u + direct edge\n",
    "        \n",
    "        self.mlp = create_mlp_v2(\n",
    "            input_dim=input_dim,\n",
    "            output_dim=1,\n",
    "            hidden_dims=[input_dim//2, input_dim//2, input_dim//2],\n",
    "            normalization_cls=torch.nn.LayerNorm,\n",
    "            activation_cls=torch.nn.ELU,\n",
    "            dropout_cls=torch.nn.Dropout,\n",
    "            dropout_prob=0.\n",
    "        )\n",
    "\n",
    "    def forward(self, data, x_out, edge_out, u_out):\n",
    "        in_ = gather_embedding(data, x_out, edge_out, u_out, self.couple_type)\n",
    "        out = self.mlp(in_)\n",
    "        out = self.scaling(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.557542Z",
     "start_time": "2019-08-25T08:30:43.533704Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.587327Z",
     "start_time": "2019-08-25T08:30:43.559159Z"
    }
   },
   "outputs": [],
   "source": [
    "class EdgeAgg(torch.nn.Module):\n",
    "    def __init__(self, dim=32):\n",
    "        super(EdgeAgg, self).__init__()\n",
    "        self.body_mlp = nn.Sequential(\n",
    "            create_mlp_v2(\n",
    "                input_dim=dim,\n",
    "                output_dim=dim*2,\n",
    "                hidden_dims=[dim*2],\n",
    "                normalization_cls=torch.nn.LayerNorm,\n",
    "                activation_cls=torch.nn.ELU,\n",
    "                dropout_cls=torch.nn.Dropout,\n",
    "                dropout_prob=0.),\n",
    "            nn.LayerNorm(dim*2)\n",
    "        )\n",
    "        \n",
    "        self.value_out = nn.Linear(dim*2, dim)\n",
    "        \n",
    "        self.gating = nn.Sequential(\n",
    "            nn.Linear(dim*2, dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, edge_out, edges_ind):\n",
    "        out = self.body_mlp(edge_out)              \n",
    "        out = self.value_out(out) * self.gating(out)\n",
    "        result = scatter_add(out, edges_ind, dim=0)        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.629982Z",
     "start_time": "2019-08-25T08:30:43.589113Z"
    }
   },
   "outputs": [],
   "source": [
    "class MegNetBlock(torch.nn.Module):\n",
    "    def __init__(self, edge_dim, x_dim, u_dim, dim=32, layer_norm=False,\n",
    "                 normalization_cls=None, activation_cls=nn.ReLU,\n",
    "                 dropout_cls=nn.Dropout, dropout_prob=0., residual=True, pooling='mean'):\n",
    "        super(MegNetBlock, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.residual = residual\n",
    "        self.pooling = pooling\n",
    "\n",
    "        if layer_norm:\n",
    "            normalization_cls = nn.LayerNorm\n",
    "        kwargs = dict(\n",
    "            normalization_cls=normalization_cls,\n",
    "            activation_cls=activation_cls,\n",
    "            dropout_cls=dropout_cls,\n",
    "            dropout_prob=dropout_prob)\n",
    "        \n",
    "        self.edge_dense = create_mlp_v2(\n",
    "            input_dim=edge_dim, output_dim=dim, hidden_dims=[dim * 2], **kwargs)\n",
    "        \n",
    "        self.edge_agg = EdgeAgg(dim=dim)\n",
    "        \n",
    "        self.node_dense = create_mlp_v2(\n",
    "            input_dim=x_dim, output_dim=dim, hidden_dims=[dim * 2], **kwargs)\n",
    "        self.global_dense = create_mlp_v2(\n",
    "            input_dim=u_dim, output_dim=dim, hidden_dims=[dim * 2], **kwargs)\n",
    "\n",
    "        self.edge_msg = create_mlp_v2(\n",
    "            input_dim=dim * 4, output_dim=dim, hidden_dims=[dim*2, dim*2], **kwargs)\n",
    "        self.node_msg = create_mlp_v2(\n",
    "            input_dim=dim * 3, output_dim=dim, hidden_dims=[dim*2, dim*2], **kwargs)\n",
    "        self.global_msg = create_mlp_v2(\n",
    "            input_dim=dim * 3, output_dim=dim, hidden_dims=[dim*2, dim*2], **kwargs)\n",
    "        \n",
    "\n",
    "    def edge_model(self, src, dest, edge_attr, u, batch):\n",
    "        # source, target: [E, F_x], where E is the number of edges.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u], where B is the number of graphs.\n",
    "        # batch: [E] with max entry B - 1.\n",
    "        out = torch.cat([src, dest, edge_attr, u[batch]], 1)\n",
    "        out = self.edge_msg(out)\n",
    "        return out\n",
    "\n",
    "    def node_model(self, x, edge_index, edge_attr, u, batch):\n",
    "        # x: [N, F_x], where N is the number of nodes.\n",
    "        # edge_index: [2, E] with max entry N - 1.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u]\n",
    "        # batch: [N] with max entry B - 1.\n",
    "        row, _ = edge_index\n",
    "        out = self.edge_agg(edge_attr, row)\n",
    "        out = torch.cat([out, x, u[batch]], dim=1)\n",
    "        out = self.node_msg(out)\n",
    "        return out\n",
    "\n",
    "    def global_model(self, x, edge_index, edge_attr, u, batch):\n",
    "        # x: [N, F_x], where N is the number of nodes.\n",
    "        # edge_index: [2, E] with max entry N - 1.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u]\n",
    "        # batch: [N] with max entry B - 1.\n",
    "        row, _ = edge_index\n",
    "        edge_mean = scatter_mean(edge_attr, batch[row], dim=0)\n",
    "        out = torch.cat(\n",
    "            [u, scatter_mean(x, batch, dim=0), edge_mean], dim=1)\n",
    "        out = self.global_msg(out)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr, u, batch, first_block=False):\n",
    "\n",
    "        # first block\n",
    "        edge_out = self.edge_dense(edge_attr)\n",
    "        x_out = self.node_dense(x)\n",
    "        u_out = self.global_dense(u)\n",
    "\n",
    "        x_res_base = x_out if first_block else x\n",
    "        edge_res_base = edge_out if first_block else edge_attr\n",
    "        u_res_base = u_out if first_block else u\n",
    "\n",
    "        row, col = edge_index        \n",
    "\n",
    "        edge_out = self.edge_model(x_out[row], x_out[col], edge_out, u_out,\n",
    "                                   batch[row])\n",
    "        if self.residual:\n",
    "            edge_out = edge_res_base + edge_out\n",
    "\n",
    "        x_out = self.node_model(x_out, edge_index, edge_out, u_out, batch)\n",
    "        if self.residual:\n",
    "            x_out = x_res_base + x_out\n",
    "\n",
    "        u_out = self.global_model(x_out, edge_index, edge_out, u_out, batch)\n",
    "        if self.residual:\n",
    "            u_out = u_res_base + u_out\n",
    "\n",
    "        return x_out, edge_out, u_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.657520Z",
     "start_time": "2019-08-25T08:30:43.631757Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiplicativeGaussianNoise(torch.nn.Module):\n",
    "    def __init__(self, scale=0.):\n",
    "        super(MultiplicativeGaussianNoise, self).__init__()\n",
    "        self.scale = scale\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if not self.training:\n",
    "            return x\n",
    "        noise = 1 + torch.randn_like(x) * self.scale\n",
    "        return x * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.696997Z",
     "start_time": "2019-08-25T08:30:43.659392Z"
    }
   },
   "outputs": [],
   "source": [
    "class MegNetModel_new(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 edge_dim,\n",
    "                 x_dim,\n",
    "                 u_dim,\n",
    "                 dim=32,\n",
    "                 head_dim=32,\n",
    "                 n_megnet_blocks=3,\n",
    "                 y_mean=0,\n",
    "                 y_std=1,\n",
    "                 layer_norm=False):\n",
    "        super(MegNetModel_new, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.n_megnet_blocks = n_megnet_blocks\n",
    "        \n",
    "        self.node_proj = torch.nn.Linear(x_dim, dim)\n",
    "        self.edge_proj = torch.nn.Linear(edge_dim, dim)\n",
    "        self.global_proj = torch.nn.Linear(u_dim, dim)\n",
    "        \n",
    "        self.megnet_blocks = torch.nn.ModuleList([\n",
    "            MegNetBlock(dim,\n",
    "                        dim,\n",
    "                        dim,\n",
    "                        dim,\n",
    "                        normalization_cls=torch.nn.LayerNorm,\n",
    "                        activation_cls=torch.nn.ELU,\n",
    "                        dropout_cls=torch.nn.Dropout,\n",
    "                        dropout_prob=0.,\n",
    "                        residual=True) for i in range(n_megnet_blocks)\n",
    "        ])\n",
    "\n",
    "        self.out_mlp = torch.nn.ModuleList([\n",
    "            OutputLayer_new(\n",
    "                dim,\n",
    "                head_dim,\n",
    "                y_mean=y_mean[i],\n",
    "                y_std=y_std[i],\n",
    "                couple_type=type_,\n",
    "            ) for i, type_ in enumerate(constants.TYPES_LIST)\n",
    "        ])\n",
    "        \n",
    "        self.noise = MultiplicativeGaussianNoise(scale=0.05)\n",
    "\n",
    "    def forward(self, data, add_noise=False):\n",
    "        data = correct_batch_edge_ind(data)\n",
    "        data = correct_inverse_couples_ind(data)\n",
    "        \n",
    "        if not hasattr(data, 'global_attr'):\n",
    "            data.global_attr = torch.zeros((data.num_graphs, 1),\n",
    "                                           dtype=torch.float,\n",
    "                                           device=data.x.device)\n",
    "        x_out, edge_out, u_out = self.node_proj(data.x), self.edge_proj(data.edge_attr), self.global_proj(data.global_attr)\n",
    "        \n",
    "        for i in range(self.n_megnet_blocks):\n",
    "            x_out, edge_out, u_out = self.megnet_blocks[i](\n",
    "                x_out,\n",
    "                data.edge_index,\n",
    "                edge_out,\n",
    "                u_out,\n",
    "                data.batch,\n",
    "                first_block=(i==0))\n",
    "            \n",
    "            if add_noise:\n",
    "                x_out = self.noise(x_out)\n",
    "                edge_out = self.noise(edge_out)\n",
    "                u_out = self.noise(u_out)\n",
    "\n",
    "        pred = torch.zeros_like(data.type,\n",
    "                                dtype=torch.float,\n",
    "                                device=x_out.device)\n",
    "        for type_ in range(8):\n",
    "            if (data.type == type_).any():\n",
    "                pred[data.type == type_] = self.out_mlp[type_](data, x_out,\n",
    "                                                               edge_out,\n",
    "                                                               u_out).view(-1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.732880Z",
     "start_time": "2019-08-25T08:30:43.698896Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_champs.metrics import MeanLogGroupMAE, AverageMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.761160Z",
     "start_time": "2019-08-25T08:30:43.734950Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_champs.training import train_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.788411Z",
     "start_time": "2019-08-25T08:30:43.763073Z"
    }
   },
   "outputs": [],
   "source": [
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.821414Z",
     "start_time": "2019-08-25T08:30:43.790368Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "def train_epoch(global_iteration, epoch, model, device, optimizer, \n",
    "                train_loader, tb_logger, gradient_accumulation_steps=1, swa=False, noise=False):\n",
    "    model.train()\n",
    "    avg_loss = AverageMetric()\n",
    "    log_mae = MeanLogGroupMAE()\n",
    "    \n",
    "    pbar = tqdm(train_loader)\n",
    "    for step, data in enumerate(pbar):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        pred = model(data, add_noise=noise)\n",
    "\n",
    "        loss = torch.nn.L1Loss(reduction='mean')(pred.view(-1),\n",
    "                                                     data.y.view(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            global_iteration += 1\n",
    "            if swa:\n",
    "                optimizer.update_swa()\n",
    "\n",
    "        tb_logger.add_scalar('loss', loss.item(), global_iteration)\n",
    "\n",
    "        avg_loss.update(loss.item() * data.num_graphs, data.num_graphs)\n",
    "        log_mae.update(pred.view(-1), data.y.view(-1), data.type)\n",
    "\n",
    "        pbar.set_postfix_str(f'loss: {avg_loss.compute():.4f}')\n",
    "    return avg_loss.compute(), log_mae, global_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:43.856321Z",
     "start_time": "2019-08-25T08:30:43.823262Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, loader):\n",
    "    model.eval()\n",
    "    log_mae = MeanLogGroupMAE()\n",
    "    avg_loss = AverageMetric()\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            pred = model(data)\n",
    "            \n",
    "            loss = torch.nn.L1Loss(reduction='mean')(pred.view(-1),\n",
    "                                                     data.y.view(-1))\n",
    "            avg_loss.update(loss.item() * data.num_graphs, data.num_graphs)\n",
    "            \n",
    "            log_mae.update(pred.view(-1), data.y.view(-1), data.type.view(-1))\n",
    "            \n",
    "        return avg_loss.compute(), log_mae\n",
    "\n",
    "\n",
    "def make_log(epoch, lr, loss, tr_logmae, val_logmae):\n",
    "    results = {\n",
    "        'epoch': epoch,\n",
    "        'lr': lr,\n",
    "        'loss': loss,\n",
    "        'tr_logmae': tr_logmae.compute(),\n",
    "        'val_logmae': val_logmae.compute(),\n",
    "    }\n",
    "    for k, v in tr_logmae.compute_individuals().items():\n",
    "        results.update({'tr_' + k: v})\n",
    "    for k, v in val_logmae.compute_individuals().items():\n",
    "        results.update({'val_' + k: v})\n",
    "    return results\n",
    "\n",
    "\n",
    "def save_checkpoint(dir_path, model, optimizer, scheduler, epoch):\n",
    "    torch.save(model.state_dict(), dir_path + f'model_epoch_{epoch}.pth')\n",
    "    torch.save(optimizer.state_dict(),\n",
    "               dir_path + f'optimizer_epoch_{epoch}.pth')\n",
    "    torch.save(scheduler.state_dict(),\n",
    "               dir_path + f'scheduler_epoch_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:44.141131Z",
     "start_time": "2019-08-25T08:30:43.858002Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:44.171319Z",
     "start_time": "2019-08-25T08:30:44.143224Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:30:44.196589Z",
     "start_time": "2019-08-25T08:30:44.173027Z"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = './models/megnet_256x10_new_arch_3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T06:10:07.473229Z",
     "start_time": "2019-08-21T06:10:06.623925Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:31:54.545873Z",
     "start_time": "2019-08-25T08:31:54.484221Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_logger = SummaryWriter(OUTPUT_DIR+'tb_log/')\n",
    "global_iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:31:54.883783Z",
     "start_time": "2019-08-25T08:31:54.856575Z"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_INTERVAL = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:31:55.132434Z",
     "start_time": "2019-08-25T08:31:55.105625Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_EPOCH = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:31:55.376268Z",
     "start_time": "2019-08-25T08:31:55.347032Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=64,\n",
    "                        shuffle=False,\n",
    "                        num_workers=8,\n",
    "                        follow_batch=[\n",
    "                            'bonds_edge_ind',\n",
    "                            'bonds_links_edge_ind',\n",
    "                            'paths_edge_ind',\n",
    "                            'couples_edge_ind',\n",
    "                            'inverse_couple_ind',\n",
    "                        ])\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=32,\n",
    "                          num_workers=8,\n",
    "                          shuffle=True,\n",
    "                          follow_batch=[\n",
    "                              'bonds_edge_ind',\n",
    "                              'bonds_links_edge_ind',\n",
    "                              'paths_edge_ind',\n",
    "                              'couples_edge_ind',\n",
    "                              'inverse_couple_ind',\n",
    "                          ], drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:31:59.921198Z",
     "start_time": "2019-08-25T08:31:55.712960Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:31:59.957295Z",
     "start_time": "2019-08-25T08:31:59.923333Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = correct_batch_edge_ind(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:31:59.986674Z",
     "start_time": "2019-08-25T08:31:59.959286Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = correct_inverse_couples_ind(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:32:00.016771Z",
     "start_time": "2019-08-25T08:31:59.988627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(batch=[895], bonds_edge_ind=[1758, 1], bonds_edge_ind_batch=[1758], bonds_links_edge_ind=[3076, 2], bonds_links_edge_ind_batch=[3076], count_couples=[64, 1], count_edges=[64, 1], count_nodes=[64, 1], couples_edge_ind=[5146, 1], couples_edge_ind_batch=[5146], couples_ind=[5146, 2], direction=[12162, 3], dist=[12162, 1], edge_attr=[12162, 34], edge_index=[2, 12162], global_attr=[64, 1], inverse_couple_ind=[5146], inverse_couple_ind_batch=[5146], mol_ind=[64, 1], paths_edge_ind=[5146, 3], paths_edge_ind_batch=[5146], paths_index=[4, 5146], pos=[895, 3], sample_weight=[5146], type=[5146], x=[895, 28], y=[5146, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:32:00.046751Z",
     "start_time": "2019-08-25T08:32:00.018253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((batch.y[batch.inverse_couple_ind] - batch.y) != 0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:32:01.123414Z",
     "start_time": "2019-08-25T08:32:00.048287Z"
    }
   },
   "outputs": [],
   "source": [
    "y_mean = train.groupby(train.type.map(\n",
    "    constants.TYPES_DICT)).scalar_coupling_constant.mean().sort_index().values\n",
    "y_std = train.groupby(train.type.map(\n",
    "    constants.TYPES_DICT)).scalar_coupling_constant.std().sort_index().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:32:05.812741Z",
     "start_time": "2019-08-25T08:32:01.124998Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = MegNetModel_new(edge_dim=data.edge_attr.size()[1],\n",
    "                    x_dim=data.x.size()[1],\n",
    "                    u_dim=1,\n",
    "                    dim=300,\n",
    "                    head_dim=300,\n",
    "                    n_megnet_blocks=10,\n",
    "                    y_mean=y_mean,\n",
    "                    y_std=y_std,\n",
    "                    layer_norm=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:32:05.841651Z",
     "start_time": "2019-08-25T08:32:05.814848Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_champs.optimizer import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T17:17:20.336495Z",
     "start_time": "2019-08-24T17:17:20.305355Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = RAdam(model.parameters(), lr=2e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T18:27:28.032626Z",
     "start_time": "2019-08-23T18:26:26.129044Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train loop\n",
    "logs = []\n",
    "for epoch in range(1, 145):\n",
    "    lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "    tr_loss, tr_logmae, global_iteration = train_epoch(global_iteration,\n",
    "                                     epoch,\n",
    "                                     model,\n",
    "                                     device,\n",
    "                                     optimizer,\n",
    "                                     train_loader,\n",
    "                                     tb_logger,\n",
    "                                     gradient_accumulation_steps=2)\n",
    "    #optimizer.update_swa()\n",
    "    scheduler.step()\n",
    "    \n",
    "    val_loss, val_logmae = test_model(model, val_loader)\n",
    "    \n",
    "    \n",
    "\n",
    "    epoch_log = make_log(epoch, lr, tr_loss, tr_logmae, val_logmae)\n",
    "    logs.append(epoch_log)\n",
    "    pd.DataFrame(logs).to_csv(OUTPUT_DIR + 'log.csv')\n",
    "    print('Epoch: {epoch:03d}, LR: {lr:7f}, Loss: {loss:.7f}, \\\n",
    "         Train LogMAE: {tr_logmae:.7f}, Val LogMAE: {val_logmae:.7f}'.format(\n",
    "        **epoch_log))    \n",
    "    \n",
    "    #optimizer.swap_swa_sgd()\n",
    "    #val_loss_swa, val_logmae_swa = test_model(model, val_loader)\n",
    "    #optimizer.swap_swa_sgd()\n",
    "    #print(f'Val LogMAE SWA: {val_logmae_swa.compute():.7f}')\n",
    "\n",
    "    if epoch % SAVE_INTERVAL == 0:\n",
    "        save_checkpoint(OUTPUT_DIR, model, optimizer, scheduler, epoch)\n",
    "\n",
    "    tb_logger.add_scalar('lr', lr, global_iteration)\n",
    "    tb_logger.add_scalar('val_loss', val_loss, global_iteration)\n",
    "    tb_logger.add_scalars('global_logmae', {\n",
    "        'tr_logmae': epoch_log['tr_logmae'],\n",
    "        'val_logmae': epoch_log['val_logmae']\n",
    "    }, global_iteration)\n",
    "\n",
    "    for type_ in constants.TYPES_LIST:\n",
    "        tb_logger.add_scalars(\n",
    "            type_, {\n",
    "                'tr_' + type_: epoch_log['tr_' + type_],\n",
    "                'val_' + type_: epoch_log['val_' + type_]\n",
    "            }, global_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T17:14:32.827720Z",
     "start_time": "2019-08-24T17:14:31.908118Z"
    }
   },
   "outputs": [],
   "source": [
    "save_checkpoint(OUTPUT_DIR, model, optimizer, scheduler, epoch=145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T17:17:31.328953Z",
     "start_time": "2019-08-24T17:17:31.301383Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer.param_groups[0]['lr'] = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T17:17:32.827457Z",
     "start_time": "2019-08-24T17:17:32.799417Z"
    }
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-24T17:17:35.344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39108b58b98b4469acbb6f8171d9c991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train loop\n",
    "logs = []\n",
    "for epoch in range(146, 168):\n",
    "    lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "    tr_loss, tr_logmae, global_iteration = train_epoch(global_iteration,\n",
    "                                     epoch,\n",
    "                                     model,\n",
    "                                     device,\n",
    "                                     optimizer,\n",
    "                                     train_loader,\n",
    "                                     tb_logger,\n",
    "                                     gradient_accumulation_steps=1)\n",
    "    #optimizer.update_swa()\n",
    "    scheduler.step()\n",
    "    \n",
    "    val_loss, val_logmae = test_model(model, val_loader)\n",
    "    \n",
    "    \n",
    "\n",
    "    epoch_log = make_log(epoch, lr, tr_loss, tr_logmae, val_logmae)\n",
    "    logs.append(epoch_log)\n",
    "    pd.DataFrame(logs).to_csv(OUTPUT_DIR + 'log.csv')\n",
    "    print('Epoch: {epoch:03d}, LR: {lr:7f}, Loss: {loss:.7f}, \\\n",
    "         Train LogMAE: {tr_logmae:.7f}, Val LogMAE: {val_logmae:.7f}'.format(\n",
    "        **epoch_log))    \n",
    "    \n",
    "    #optimizer.swap_swa_sgd()\n",
    "    #val_loss_swa, val_logmae_swa = test_model(model, val_loader)\n",
    "    #optimizer.swap_swa_sgd()\n",
    "    #print(f'Val LogMAE SWA: {val_logmae_swa.compute():.7f}')\n",
    "\n",
    "    if epoch % SAVE_INTERVAL == 0:\n",
    "        save_checkpoint(OUTPUT_DIR, model, optimizer, scheduler, epoch)\n",
    "\n",
    "    tb_logger.add_scalar('lr', lr, global_iteration)\n",
    "    tb_logger.add_scalar('val_loss', val_loss, global_iteration)\n",
    "    tb_logger.add_scalars('global_logmae', {\n",
    "        'tr_logmae': epoch_log['tr_logmae'],\n",
    "        'val_logmae': epoch_log['val_logmae']\n",
    "    }, global_iteration)\n",
    "\n",
    "    for type_ in constants.TYPES_LIST:\n",
    "        tb_logger.add_scalars(\n",
    "            type_, {\n",
    "                'tr_' + type_: epoch_log['tr_' + type_],\n",
    "                'val_' + type_: epoch_log['val_' + type_]\n",
    "            }, global_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T00:42:49.668916Z",
     "start_time": "2019-08-25T00:42:48.233898Z"
    }
   },
   "outputs": [],
   "source": [
    "save_checkpoint(OUTPUT_DIR, model, optimizer, scheduler, epoch=168)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:32:14.627644Z",
     "start_time": "2019-08-25T08:32:14.599610Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_direction(df):\n",
    "    inverse_direction = df.rename(\n",
    "        {\n",
    "            'atom_index_1': 'atom_index_0',\n",
    "            'atom_index_0': 'atom_index_1'\n",
    "        },\n",
    "        axis=1)\n",
    "    merged = pd.merge(df,\n",
    "                      inverse_direction,\n",
    "                      on=['molecule_name', 'atom_index_0', 'atom_index_1'],\n",
    "                      suffixes=('', '_bis'))\n",
    "    merged['scalar_coupling_constant'] = (merged['scalar_coupling_constant'] + merged['scalar_coupling_constant_bis']) / 2\n",
    "    return merged.drop('scalar_coupling_constant_bis', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:34:29.673856Z",
     "start_time": "2019-08-25T08:34:29.637817Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, input_data, checkpoint_path):\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    pred_dataset = MoleculeDataset(\n",
    "        metadata=input_data,\n",
    "        base_dir=constants.STRUCT_DATA_PATH,\n",
    "                             transform=T.Compose([\n",
    "                                  AddBondPath(),\n",
    "                                  AddVirtualEdges(),\n",
    "                                  AddEdgeDistanceAndDirection(dist_noise=0.),\n",
    "                                  AddGlobalAttr(),\n",
    "                                  SortTarget(),\n",
    "                                  AddBondLinks(),\n",
    "                                  AddCounts(),\n",
    "                                  AddInverseCouples(),\n",
    "                              ]))\n",
    "    pred_loader = DataLoader(pred_dataset,\n",
    "                             batch_size=64,\n",
    "                             shuffle=False,\n",
    "                             num_workers=8,\n",
    "                             follow_batch=[\n",
    "                                 'bonds_edge_ind', 'bonds_links_edge_ind',\n",
    "                                 'paths_edge_ind', 'couples_edge_ind', 'inverse_couple_ind'\n",
    "                             ])\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    inds = []\n",
    "    couples = []\n",
    "    for data in tqdm(pred_loader):\n",
    "        with torch.no_grad():\n",
    "            data = data.to(device)\n",
    "            pred = model(data).detach().cpu().numpy()\n",
    "            ind = data.mol_ind[data.couples_edge_ind_batch].detach().cpu().numpy()\n",
    "\n",
    "            couple_ind = data.couples_ind.cpu().numpy()\n",
    "            df = pd.DataFrame({\n",
    "                'molecule_name' : pred_dataset.molecules[ind].ravel(),\n",
    "                'molecule_ind': ind.ravel(),\n",
    "                'atom_index_0': couple_ind[:,0].ravel(), \n",
    "                'atom_index_1': couple_ind[:,1].ravel(),\n",
    "            })\n",
    "            df.sort_values(['molecule_ind', 'atom_index_0', 'atom_index_1'], ascending=True, inplace=True)\n",
    "            np.testing.assert_array_equal(df.molecule_ind, ind.ravel())\n",
    "            df['scalar_coupling_constant'] = pred\n",
    "            preds.append(df.drop('molecule_ind', axis=1))\n",
    "            \n",
    "    pred = pd.concat(preds)\n",
    "    pred = merge_direction(pred)\n",
    "    merged = pd.merge(input_data,\n",
    "                  pred,\n",
    "                  on=['molecule_name', 'atom_index_0', 'atom_index_1'],\n",
    "                  how='left', suffixes=('_truth', ''))\n",
    "    assert merged.dropna().shape[0] == input_data.shape[0]\n",
    "    return merged.loc[:, ['id', 'scalar_coupling_constant']].set_index('id'), pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:35:00.886568Z",
     "start_time": "2019-08-25T08:34:30.535707Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8738d2020c6e4198a56411d42ce411d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b377b3a1d243b494154f1c92985e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_val, p = predict(model, val_data, f'{OUTPUT_DIR}/model_epoch_168.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:35:03.092381Z",
     "start_time": "2019-08-25T08:35:03.057118Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>-1.005834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>0.456203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>0.455955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>14.321383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>92.641945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scalar_coupling_constant\n",
       "id                            \n",
       "1582                 -1.005834\n",
       "1583                  0.456203\n",
       "1584                  0.455955\n",
       "1585                 14.321383\n",
       "1586                 92.641945"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:35:04.192263Z",
     "start_time": "2019-08-25T08:35:04.162362Z"
    }
   },
   "outputs": [],
   "source": [
    "def score(pred, ref_data):\n",
    "    merged = pd.merge(ref_data, pred, how='left', left_on='id', right_index=True, suffixes=('', '_pred'))\n",
    "    merged['abs_error'] = (merged['scalar_coupling_constant'] - merged['scalar_coupling_constant_pred']).abs()\n",
    "    result = merged.groupby('type')['abs_error'].mean()\n",
    "    result.iloc[:] = np.log(np.maximum(result.values, 1e-9))\n",
    "    return result.mean(), result.to_dict()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:35:05.615382Z",
     "start_time": "2019-08-25T08:35:05.477640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.7105617144537737,\n",
       " {'1JHC': -1.759798528496549,\n",
       "  '1JHN': -1.7263141403697904,\n",
       "  '2JHC': -2.724144449858338,\n",
       "  '2JHH': -3.1877947458752223,\n",
       "  '2JHN': -3.036704517513776,\n",
       "  '3JHC': -2.688196383634799,\n",
       "  '3JHH': -3.2627320895307594,\n",
       "  '3JHN': -3.2988088603509516})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(pred_val, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:35:12.071396Z",
     "start_time": "2019-08-25T08:35:10.561812Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:39:38.431349Z",
     "start_time": "2019-08-25T08:35:24.283891Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e26f0944c5042789292948db78733c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45772), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d190fa3d14574e2f8139c4641081f863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=716), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sub, _ = predict(model, test, f'{OUTPUT_DIR}/model_epoch_168.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:39:38.470598Z",
     "start_time": "2019-08-25T08:39:38.435216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4658147</th>\n",
       "      <td>19.008881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658148</th>\n",
       "      <td>189.977356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658149</th>\n",
       "      <td>11.732316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658150</th>\n",
       "      <td>189.975189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658151</th>\n",
       "      <td>19.008661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scalar_coupling_constant\n",
       "id                               \n",
       "4658147                 19.008881\n",
       "4658148                189.977356\n",
       "4658149                 11.732316\n",
       "4658150                189.975189\n",
       "4658151                 19.008661"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:40:04.443170Z",
     "start_time": "2019-08-25T08:40:03.790933Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p subs/lam_03_v1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:40:11.414581Z",
     "start_time": "2019-08-25T08:40:04.584157Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.to_csv('./subs/lam_03_v1/sub.csv', index=True)\n",
    "pred_val.to_csv('./subs/lam_03_v1/pred_val.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
