{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:44:49.030914Z",
     "start_time": "2019-09-13T09:44:49.018367Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:44:49.714802Z",
     "start_time": "2019-09-13T09:44:49.032251Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "from tqdm.autonotebook import tqdm\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GroupKFold\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import HuberRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:44:49.730758Z",
     "start_time": "2019-09-13T09:44:49.716492Z"
    }
   },
   "outputs": [],
   "source": [
    "script_dir = osp.abspath(os.path.dirname(__file__))\n",
    "DATA_DIR = script_dir + '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:44:53.094764Z",
     "start_time": "2019-09-13T09:44:49.732120Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test = pd.read_csv(f'{DATA_DIR}/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Split train valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:44:53.290127Z",
     "start_time": "2019-09-13T09:44:53.095738Z"
    }
   },
   "outputs": [],
   "source": [
    "molecules = train.molecule_name.drop_duplicates().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:44:53.306229Z",
     "start_time": "2019-09-13T09:44:53.291106Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ind, valid_ind = train_test_split(np.arange(len(molecules)),\n",
    "                                        test_size=5000,\n",
    "                                        random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train valid subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:44:53.913980Z",
     "start_time": "2019-09-13T09:44:53.307164Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train.loc[train.molecule_name.isin(molecules.iloc[train_ind])]\n",
    "val_data = train.loc[train.molecule_name.isin(molecules.iloc[valid_ind])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:44:53.962783Z",
     "start_time": "2019-09-13T09:44:53.915598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>1582</td>\n",
       "      <td>dsgdb9nsd_000098</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2JHC</td>\n",
       "      <td>-1.057440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1583</td>\n",
       "      <td>dsgdb9nsd_000098</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3JHC</td>\n",
       "      <td>0.474094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>1584</td>\n",
       "      <td>dsgdb9nsd_000098</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3JHC</td>\n",
       "      <td>0.473745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>1585</td>\n",
       "      <td>dsgdb9nsd_000098</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3JHH</td>\n",
       "      <td>14.369600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>1586</td>\n",
       "      <td>dsgdb9nsd_000098</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>92.785800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     molecule_name  atom_index_0  atom_index_1  type  \\\n",
       "1582  1582  dsgdb9nsd_000098             5             1  2JHC   \n",
       "1583  1583  dsgdb9nsd_000098             5             2  3JHC   \n",
       "1584  1584  dsgdb9nsd_000098             5             4  3JHC   \n",
       "1585  1585  dsgdb9nsd_000098             5             6  3JHH   \n",
       "1586  1586  dsgdb9nsd_000098             6             1  1JHC   \n",
       "\n",
       "      scalar_coupling_constant  \n",
       "1582                 -1.057440  \n",
       "1583                  0.474094  \n",
       "1584                  0.473745  \n",
       "1585                 14.369600  \n",
       "1586                 92.785800  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:44:53.979243Z",
     "start_time": "2019-09-13T09:44:53.964563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['guillaume/train_9ZB-015-link-edges-lowerlr.256000.csv',\n",
       " 'guillaume/train_9ZG4A-000-vanilla-deep-radam-droplr-2.518044.csv',\n",
       " 'guillaume/train_9ZF3-004-ablation-study-remove-global-state-5-droplr.275100.csv',\n",
       " 'guillaume/train_9ZF2-005-ablation-study-high-batch-size-augment-really-this-time-4-droplr.278759.csv',\n",
       " 'guillaume/train_9ZB2-003-link-edges-4xlowerlr-2-droplr.634290.csv',\n",
       " 'guillaume/train_9ZG4A-001-vanilla-deep-radam-droplr.515360.csv',\n",
       " 'guillaume/train_9ZF5-004-ablation-study-no-pairs-embeddings-and-one-preprocessing-edge-pairs-5-droplr.303008.csv',\n",
       " 'guillaume/train_9ZF-002-ablation-study-high-batch-size-3-droplr.593979.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob(script_dir + '/guillaume/train*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:44:53.995598Z",
     "start_time": "2019-09-13T09:44:53.980456Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_list_prediction(folder_path, text_find, text_replace):\n",
    "    sub_val = []\n",
    "    sub_test = []\n",
    "    for sub_val_path in glob(folder_path):\n",
    "        sub_val.append(sub_val_path)\n",
    "        sub_test.append(sub_val_path.replace(text_find, text_replace))\n",
    "    \n",
    "    return sub_val, sub_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:44:54.011132Z",
     "start_time": "2019-09-13T09:44:53.996629Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_pred_guillaume(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df.loc[df.dataset=='valid', ['id', 'prediction']].set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:44:54.027358Z",
     "start_time": "2019-09-13T09:44:54.012326Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_pred_lam(path):\n",
    "    return pd.read_csv(path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:44:54.042521Z",
     "start_time": "2019-09-13T09:44:54.028536Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_pred_thanhtu(path):\n",
    "    return pd.read_csv(path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:45:26.590884Z",
     "start_time": "2019-09-13T09:44:54.043546Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_val = pd.concat([\n",
    "    *[load_pred_guillaume(path) for path in create_list_prediction(script_dir + '/guillaume/train*.csv', 'train', 'submission')[0]],\n",
    "    *[load_pred_lam(path) for path in create_list_prediction(script_dir + '/lam_01_v1/pred*.csv', 'pred', 'sub')[0]],\n",
    "    *[load_pred_thanhtu(path) for path in create_list_prediction(script_dir + '/thanhtu/valid*.csv', 'valid', 'sub')[0]]\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:45:34.430806Z",
     "start_time": "2019-09-13T09:45:26.591904Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "preds_test = pd.concat([\n",
    "    *[load_pred_lam(path) for path in create_list_prediction(script_dir + '/guillaume/train*.csv', 'train', 'submission')[1]],\n",
    "    *[load_pred_lam(path) for path in create_list_prediction(script_dir + '/lam_01_v1/pred*.csv', 'pred_val', 'sub')[1]],\n",
    "    *[load_pred_thanhtu(path) for path in create_list_prediction(script_dir + '/thanhtu/valid*.csv', 'valid', 'sub')[1]]\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:45:34.446274Z",
     "start_time": "2019-09-13T09:45:34.431776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((275505, 14), (2505542, 14))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_val.shape, preds_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:52:40.966004Z",
     "start_time": "2019-09-13T09:45:54.006901Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0535833\tvalid_0's l1: 0.0535833\n",
      "[200]\tvalid_0's l1: 0.0532768\tvalid_0's l1: 0.0532768\n",
      "[300]\tvalid_0's l1: 0.053114\tvalid_0's l1: 0.053114\n",
      "[400]\tvalid_0's l1: 0.0530188\tvalid_0's l1: 0.0530188\n",
      "[500]\tvalid_0's l1: 0.0529418\tvalid_0's l1: 0.0529418\n",
      "Early stopping, best iteration is:\n",
      "[555]\tvalid_0's l1: 0.0529062\tvalid_0's l1: 0.0529062\n",
      "-2.9392349486366625\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0534275\tvalid_0's l1: 0.0534275\n",
      "[200]\tvalid_0's l1: 0.0531135\tvalid_0's l1: 0.0531135\n",
      "[300]\tvalid_0's l1: 0.0529056\tvalid_0's l1: 0.0529056\n",
      "[400]\tvalid_0's l1: 0.0527716\tvalid_0's l1: 0.0527716\n",
      "[500]\tvalid_0's l1: 0.0526998\tvalid_0's l1: 0.0526998\n",
      "Early stopping, best iteration is:\n",
      "[540]\tvalid_0's l1: 0.0526765\tvalid_0's l1: 0.0526765\n",
      "-2.943585012375487\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0482548\tvalid_0's l1: 0.0482548\n",
      "[200]\tvalid_0's l1: 0.0480156\tvalid_0's l1: 0.0480156\n",
      "[300]\tvalid_0's l1: 0.0478732\tvalid_0's l1: 0.0478732\n",
      "[400]\tvalid_0's l1: 0.0478065\tvalid_0's l1: 0.0478065\n",
      "[500]\tvalid_0's l1: 0.0477559\tvalid_0's l1: 0.0477559\n",
      "Early stopping, best iteration is:\n",
      "[582]\tvalid_0's l1: 0.0477253\tvalid_0's l1: 0.0477253\n",
      "-3.0422931399321276\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0491315\tvalid_0's l1: 0.0491315\n",
      "[200]\tvalid_0's l1: 0.0488809\tvalid_0's l1: 0.0488809\n",
      "[300]\tvalid_0's l1: 0.0487537\tvalid_0's l1: 0.0487537\n",
      "[400]\tvalid_0's l1: 0.0486448\tvalid_0's l1: 0.0486448\n",
      "[500]\tvalid_0's l1: 0.0485786\tvalid_0's l1: 0.0485786\n",
      "[600]\tvalid_0's l1: 0.0485398\tvalid_0's l1: 0.0485398\n",
      "Early stopping, best iteration is:\n",
      "[599]\tvalid_0's l1: 0.0485396\tvalid_0's l1: 0.0485396\n",
      "-3.0253744409575174\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0534122\tvalid_0's l1: 0.0534122\n",
      "[200]\tvalid_0's l1: 0.0531347\tvalid_0's l1: 0.0531347\n",
      "[300]\tvalid_0's l1: 0.0529506\tvalid_0's l1: 0.0529506\n",
      "[400]\tvalid_0's l1: 0.0528593\tvalid_0's l1: 0.0528593\n",
      "Early stopping, best iteration is:\n",
      "[480]\tvalid_0's l1: 0.0528198\tvalid_0's l1: 0.0528198\n",
      "-2.9408697302484894\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0616748\tvalid_0's l1: 0.0616748\n",
      "[200]\tvalid_0's l1: 0.0614194\tvalid_0's l1: 0.0614194\n",
      "[300]\tvalid_0's l1: 0.0612659\tvalid_0's l1: 0.0612659\n",
      "[400]\tvalid_0's l1: 0.0611715\tvalid_0's l1: 0.0611715\n",
      "[500]\tvalid_0's l1: 0.0611062\tvalid_0's l1: 0.0611062\n",
      "Early stopping, best iteration is:\n",
      "[540]\tvalid_0's l1: 0.0610916\tvalid_0's l1: 0.0610916\n",
      "-2.7953801449363564\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0512835\tvalid_0's l1: 0.0512835\n",
      "[200]\tvalid_0's l1: 0.0509837\tvalid_0's l1: 0.0509837\n",
      "[300]\tvalid_0's l1: 0.050794\tvalid_0's l1: 0.050794\n",
      "[400]\tvalid_0's l1: 0.0506788\tvalid_0's l1: 0.0506788\n",
      "[500]\tvalid_0's l1: 0.0506095\tvalid_0's l1: 0.0506095\n",
      "[600]\tvalid_0's l1: 0.0505475\tvalid_0's l1: 0.0505475\n",
      "Early stopping, best iteration is:\n",
      "[655]\tvalid_0's l1: 0.0505311\tvalid_0's l1: 0.0505311\n",
      "-2.9851664897098376\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0502558\tvalid_0's l1: 0.0502558\n",
      "[200]\tvalid_0's l1: 0.0499793\tvalid_0's l1: 0.0499793\n",
      "[300]\tvalid_0's l1: 0.0498261\tvalid_0's l1: 0.0498261\n",
      "[400]\tvalid_0's l1: 0.0497284\tvalid_0's l1: 0.0497284\n",
      "[500]\tvalid_0's l1: 0.0496681\tvalid_0's l1: 0.0496681\n",
      "Early stopping, best iteration is:\n",
      "[510]\tvalid_0's l1: 0.0496637\tvalid_0's l1: 0.0496637\n",
      "-3.002481704272897\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0558015\tvalid_0's l1: 0.0558015\n",
      "[200]\tvalid_0's l1: 0.0554472\tvalid_0's l1: 0.0554472\n",
      "[300]\tvalid_0's l1: 0.0552215\tvalid_0's l1: 0.0552215\n",
      "[400]\tvalid_0's l1: 0.055084\tvalid_0's l1: 0.055084\n",
      "[500]\tvalid_0's l1: 0.0550224\tvalid_0's l1: 0.0550224\n",
      "[600]\tvalid_0's l1: 0.0549719\tvalid_0's l1: 0.0549719\n",
      "Early stopping, best iteration is:\n",
      "[609]\tvalid_0's l1: 0.0549678\tvalid_0's l1: 0.0549678\n",
      "-2.901007511753956\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0623201\tvalid_0's l1: 0.0623201\n",
      "[200]\tvalid_0's l1: 0.0619946\tvalid_0's l1: 0.0619946\n",
      "[300]\tvalid_0's l1: 0.0617855\tvalid_0's l1: 0.0617855\n",
      "[400]\tvalid_0's l1: 0.0616691\tvalid_0's l1: 0.0616691\n",
      "Early stopping, best iteration is:\n",
      "[489]\tvalid_0's l1: 0.061611\tvalid_0's l1: 0.061611\n",
      "-2.786915241681526\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0574122\tvalid_0's l1: 0.0574122\n",
      "[200]\tvalid_0's l1: 0.0571418\tvalid_0's l1: 0.0571418\n",
      "[300]\tvalid_0's l1: 0.0569348\tvalid_0's l1: 0.0569348\n",
      "[400]\tvalid_0's l1: 0.0568232\tvalid_0's l1: 0.0568232\n",
      "[500]\tvalid_0's l1: 0.0567383\tvalid_0's l1: 0.0567383\n",
      "[600]\tvalid_0's l1: 0.0566912\tvalid_0's l1: 0.0566912\n",
      "[700]\tvalid_0's l1: 0.0566571\tvalid_0's l1: 0.0566571\n",
      "Early stopping, best iteration is:\n",
      "[755]\tvalid_0's l1: 0.0566387\tvalid_0's l1: 0.0566387\n",
      "-2.871063588411088\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0519651\tvalid_0's l1: 0.0519651\n",
      "[200]\tvalid_0's l1: 0.0516618\tvalid_0's l1: 0.0516618\n",
      "[300]\tvalid_0's l1: 0.0514654\tvalid_0's l1: 0.0514654\n",
      "[400]\tvalid_0's l1: 0.0513399\tvalid_0's l1: 0.0513399\n",
      "[500]\tvalid_0's l1: 0.0512682\tvalid_0's l1: 0.0512682\n",
      "[600]\tvalid_0's l1: 0.051224\tvalid_0's l1: 0.051224\n",
      "[700]\tvalid_0's l1: 0.0511983\tvalid_0's l1: 0.0511983\n",
      "Early stopping, best iteration is:\n",
      "[709]\tvalid_0's l1: 0.0511952\tvalid_0's l1: 0.0511952\n",
      "-2.972108658546897\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0579627\tvalid_0's l1: 0.0579627\n",
      "[200]\tvalid_0's l1: 0.057664\tvalid_0's l1: 0.057664\n",
      "[300]\tvalid_0's l1: 0.0574738\tvalid_0's l1: 0.0574738\n",
      "[400]\tvalid_0's l1: 0.0573541\tvalid_0's l1: 0.0573541\n",
      "[500]\tvalid_0's l1: 0.057282\tvalid_0's l1: 0.057282\n",
      "[600]\tvalid_0's l1: 0.0572299\tvalid_0's l1: 0.0572299\n",
      "Early stopping, best iteration is:\n",
      "[641]\tvalid_0's l1: 0.0572112\tvalid_0's l1: 0.0572112\n",
      "-2.86100574211878\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0506637\tvalid_0's l1: 0.0506637\n",
      "[200]\tvalid_0's l1: 0.0503834\tvalid_0's l1: 0.0503834\n",
      "[300]\tvalid_0's l1: 0.0502474\tvalid_0's l1: 0.0502474\n",
      "[400]\tvalid_0's l1: 0.0501731\tvalid_0's l1: 0.0501731\n",
      "Early stopping, best iteration is:\n",
      "[483]\tvalid_0's l1: 0.0501385\tvalid_0's l1: 0.0501385\n",
      "-2.992966317829681\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0478229\tvalid_0's l1: 0.0478229\n",
      "[200]\tvalid_0's l1: 0.0475471\tvalid_0's l1: 0.0475471\n",
      "[300]\tvalid_0's l1: 0.047357\tvalid_0's l1: 0.047357\n",
      "[400]\tvalid_0's l1: 0.0472522\tvalid_0's l1: 0.0472522\n",
      "[500]\tvalid_0's l1: 0.0471781\tvalid_0's l1: 0.0471781\n",
      "Early stopping, best iteration is:\n",
      "[579]\tvalid_0's l1: 0.0471504\tvalid_0's l1: 0.0471504\n",
      "-3.0544117480055255\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0511497\tvalid_0's l1: 0.0511497\n",
      "[200]\tvalid_0's l1: 0.0508806\tvalid_0's l1: 0.0508806\n",
      "[300]\tvalid_0's l1: 0.0507315\tvalid_0's l1: 0.0507315\n",
      "[400]\tvalid_0's l1: 0.0506583\tvalid_0's l1: 0.0506583\n",
      "[500]\tvalid_0's l1: 0.0505997\tvalid_0's l1: 0.0505997\n",
      "[600]\tvalid_0's l1: 0.0505701\tvalid_0's l1: 0.0505701\n",
      "Early stopping, best iteration is:\n",
      "[620]\tvalid_0's l1: 0.0505632\tvalid_0's l1: 0.0505632\n",
      "-2.9845309059776834\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0481334\tvalid_0's l1: 0.0481334\n",
      "[200]\tvalid_0's l1: 0.0479414\tvalid_0's l1: 0.0479414\n",
      "[300]\tvalid_0's l1: 0.0478012\tvalid_0's l1: 0.0478012\n",
      "[400]\tvalid_0's l1: 0.0477051\tvalid_0's l1: 0.0477051\n",
      "[500]\tvalid_0's l1: 0.047649\tvalid_0's l1: 0.047649\n",
      "Early stopping, best iteration is:\n",
      "[507]\tvalid_0's l1: 0.047644\tvalid_0's l1: 0.047644\n",
      "-3.043998210979757\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0572258\tvalid_0's l1: 0.0572258\n",
      "[200]\tvalid_0's l1: 0.0569497\tvalid_0's l1: 0.0569497\n",
      "[300]\tvalid_0's l1: 0.0567539\tvalid_0's l1: 0.0567539\n",
      "[400]\tvalid_0's l1: 0.0566217\tvalid_0's l1: 0.0566217\n",
      "[500]\tvalid_0's l1: 0.0565494\tvalid_0's l1: 0.0565494\n",
      "[600]\tvalid_0's l1: 0.0565149\tvalid_0's l1: 0.0565149\n",
      "Early stopping, best iteration is:\n",
      "[681]\tvalid_0's l1: 0.056492\tvalid_0's l1: 0.056492\n",
      "-2.8736558803710386\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0522574\tvalid_0's l1: 0.0522574\n",
      "[200]\tvalid_0's l1: 0.0519719\tvalid_0's l1: 0.0519719\n",
      "[300]\tvalid_0's l1: 0.0517828\tvalid_0's l1: 0.0517828\n",
      "[400]\tvalid_0's l1: 0.0516747\tvalid_0's l1: 0.0516747\n",
      "[500]\tvalid_0's l1: 0.0516017\tvalid_0's l1: 0.0516017\n",
      "Early stopping, best iteration is:\n",
      "[506]\tvalid_0's l1: 0.0515994\tvalid_0's l1: 0.0515994\n",
      "-2.96424508040375\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's l1: 0.0567839\tvalid_0's l1: 0.0567839\n",
      "[200]\tvalid_0's l1: 0.0564706\tvalid_0's l1: 0.0564706\n",
      "[300]\tvalid_0's l1: 0.0562876\tvalid_0's l1: 0.0562876\n",
      "[400]\tvalid_0's l1: 0.056187\tvalid_0's l1: 0.056187\n",
      "[500]\tvalid_0's l1: 0.0561251\tvalid_0's l1: 0.0561251\n",
      "Early stopping, best iteration is:\n",
      "[577]\tvalid_0's l1: 0.0560991\tvalid_0's l1: 0.0560991\n",
      "-2.8806353001161114\n"
     ]
    }
   ],
   "source": [
    "preds = preds_val.loc[val_data['id']]\n",
    "val_xgb = val_data.copy()\n",
    "val_xgb['scalar_coupling_constant'] = 0\n",
    "val_xgb = val_xgb.reset_index()\n",
    "X = preds.values\n",
    "y = val_data.scalar_coupling_constant.values\n",
    "test_pred_xgb = test.copy()\n",
    "test_pred_xgb['scalar_coupling_constant'] = 0\n",
    "test_pred_xgb = test_pred_xgb.reset_index()\n",
    "Xtest = preds_test.loc[test['id']].values\n",
    "groups = val_xgb.molecule_name.astype('category').cat.codes.values\n",
    "# types = val.type.astype('category').cat.codes.values\n",
    "\n",
    "cv = GroupKFold(20)\n",
    "for train_index, val_index in cv.split(X, y, groups):\n",
    "    clf = LGBMRegressor(\n",
    "        num_leaves=60,\n",
    "        max_depth=-1,\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=20000,\n",
    "        subsample_for_bin=200000,\n",
    "        objective='regression_l1',\n",
    "        reg_alpha=0.0,\n",
    "        random_state=None,\n",
    "        n_jobs=12,\n",
    "        silent=False,\n",
    "        )\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "#     type_train, type_val = types[train_index], types[val_index]\n",
    "\n",
    "    clf.fit(\n",
    "            np.concatenate([\n",
    "                X_train - X_train.mean(axis=1).reshape(-1, 1),\n",
    "                X_train, \n",
    "#                 type_train.reshape(-1, 1)\n",
    "            ], axis = 1\n",
    "            ),\n",
    "            y_train - X_train.mean(axis = 1),\n",
    "            eval_set = [\n",
    "                (\n",
    "                    np.concatenate(\n",
    "                    [\n",
    "                        X_val - X_val.mean(axis = 1).reshape(-1, 1),\n",
    "                        X_val,\n",
    "#                         type_val.reshape(-1, 1)\n",
    "                    ], axis = 1\n",
    "                    ),\n",
    "                    y_val - X_val.mean(axis = 1)\n",
    "                )\n",
    "            ],\n",
    "            eval_metric = ['mae'],\n",
    "            early_stopping_rounds = 10,\n",
    "            verbose = 100\n",
    "    )\n",
    "    res_lgbm = clf.predict(np.concatenate([X_val - X_val.mean(axis = 1).reshape(-1, 1),\n",
    "                                           X_val,\n",
    "#                                            type_val.reshape(-1, 1)\n",
    "                                          ], axis = 1)\n",
    "                                           ) + X_val.mean(axis = 1)\n",
    "\n",
    "    res_test = clf.predict(np.concatenate([\n",
    "                                           Xtest - Xtest.mean(axis = 1).reshape(-1, 1),\n",
    "                                           Xtest,\n",
    "#                                            type_test.reshape(-1, 1)\n",
    "                                        ], axis = 1)) + Xtest.mean(axis = 1)\n",
    "    \n",
    "    print(np.log(np.abs(res_lgbm - y_val).mean()))\n",
    "    val_xgb.loc[val_index, 'scalar_coupling_constant'] += res_lgbm\n",
    "    test_pred_xgb.loc[:, 'scalar_coupling_constant'] += res_test\n",
    "\n",
    "test_pred_xgb['scalar_coupling_constant'] /= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:52:40.998037Z",
     "start_time": "2019-09-13T09:52:40.967465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0863043130482577\n"
     ]
    }
   ],
   "source": [
    "val_xgb['mae'] = (val_xgb['scalar_coupling_constant'] - y).abs()\n",
    "print(np.log(val_xgb.groupby('type')['mae'].mean()).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:52:41.026636Z",
     "start_time": "2019-09-13T09:52:40.999391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "1JHC   -2.145392\n",
       "1JHN   -2.236141\n",
       "2JHC   -3.107093\n",
       "2JHH   -3.676761\n",
       "2JHN   -3.373819\n",
       "3JHC   -3.037339\n",
       "3JHH   -3.560656\n",
       "3JHN   -3.553233\n",
       "Name: mae, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(val_xgb.groupby('type')['mae'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Huberloss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-13T10:02:32.238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2JHC -3.027295782992844\n",
      "2JHC -3.1037589839104265\n",
      "2JHC -3.3142853453794454\n",
      "2JHC -3.1454979800188934\n",
      "2JHC -2.8071585767481047\n",
      "2JHC -3.0865643204827222\n",
      "2JHC -3.1934427873805165\n",
      "2JHC -3.0881499446694827\n",
      "2JHC -3.0977316505428893\n"
     ]
    }
   ],
   "source": [
    "preds = preds_val.loc[val_data['id']]\n",
    "val_huber = val_data.copy()\n",
    "val_huber['scalar_coupling_constant'] = 0\n",
    "val_huber = val_huber.reset_index()\n",
    "X = preds.values\n",
    "y = val_data.scalar_coupling_constant.values\n",
    "test_pred_huber = test.copy()\n",
    "test_pred_huber['scalar_coupling_constant'] = 0\n",
    "test_pred_huber = test_pred_huber.reset_index()\n",
    "Xtest = preds_test.loc[test['id']].values\n",
    "groups = val_huber.molecule_name.astype('category').cat.codes.values\n",
    "types = val_huber.type.astype('category').cat.codes.values\n",
    "\n",
    "for bond_type in val_huber.type.unique():\n",
    "    sub = val_huber.loc[val_huber.type == bond_type]\n",
    "    sub_groups = groups[sub.index]\n",
    "    sub_X_type = X[sub.index]\n",
    "    sub_y_type = y[sub.index]\n",
    "#     sub_types = types[sub.index]\n",
    "    \n",
    "    sub_test = test_pred_huber.loc[test_pred_huber.type == bond_type]\n",
    "    sub_Xtest = Xtest[sub_test.index]\n",
    "    \n",
    "    cv = GroupKFold(20)\n",
    "    for train_index, val_index in cv.split(sub_X_type, sub_y_type, sub_groups):        \n",
    "        clf = HuberRegressor(epsilon = 1.01, max_iter = 50000, alpha = 1e-6, tol = 1e-5)        \n",
    "        X_train, X_val = sub_X_type[train_index], sub_X_type[val_index]\n",
    "        y_train, y_val = sub_y_type[train_index], sub_y_type[val_index]        \n",
    "\n",
    "#         type_train, type_test = sub_types[train_index], sub_types[test_index]\n",
    "\n",
    "        clf.fit(\n",
    "                np.concatenate([\n",
    "                    X_train - X_train.mean(axis=1).reshape(-1, 1),\n",
    "                    X_train, \n",
    "#                     type_train.reshape(-1, 1)\n",
    "                ], axis = 1\n",
    "                ),\n",
    "                y_train - X_train.mean(axis = 1)\n",
    "        )\n",
    "        res_lgbm = clf.predict(np.concatenate([X_val - X_val.mean(axis = 1).reshape(-1, 1),\n",
    "                                               X_val,\n",
    "#                                                type_test.reshape(-1, 1)\n",
    "                                              ], axis = 1)\n",
    "                                               ) + X_val.mean(axis = 1)\n",
    "        \n",
    "        res_test = clf.predict(np.concatenate([\n",
    "                                           sub_Xtest - sub_Xtest.mean(axis = 1).reshape(-1, 1),\n",
    "                                           sub_Xtest,\n",
    "        #                                            type_test.reshape(-1, 1)\n",
    "                                        ], axis = 1)) + sub_Xtest.mean(axis = 1)\n",
    "        \n",
    "        print(bond_type, np.log(np.abs(res_lgbm - y_val).mean()))\n",
    "        val_huber.loc[sub.index[val_index], 'scalar_coupling_constant'] += res_lgbm\n",
    "        test_pred_huber.loc[sub_test.index, 'scalar_coupling_constant'] += res_test\n",
    "        \n",
    "test_pred_huber['scalar_coupling_constant'] /= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:52:41.350441Z",
     "start_time": "2019-09-13T09:46:02.394Z"
    }
   },
   "outputs": [],
   "source": [
    "val_huber['mae'] = (val_huber['scalar_coupling_constant'] - y).abs()\n",
    "print(np.log(val_huber.groupby('type')['mae'].mean()).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:52:41.351175Z",
     "start_time": "2019-09-13T09:46:02.850Z"
    }
   },
   "outputs": [],
   "source": [
    "val_huber.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:52:41.351960Z",
     "start_time": "2019-09-13T09:46:03.122Z"
    }
   },
   "outputs": [],
   "source": [
    "val_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:52:41.352635Z",
     "start_time": "2019-09-13T09:46:03.386Z"
    }
   },
   "outputs": [],
   "source": [
    "val_final = val_huber.copy()\n",
    "val_final['scalar_coupling_constant'] = val_xgb['scalar_coupling_constant'] * 0.5 + val_huber['scalar_coupling_constant'] *0.5\n",
    "val_final['mae'] = (val_final['scalar_coupling_constant'] - y).abs()\n",
    "print(np.log(val_final.groupby('type')['mae'].mean()).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:52:41.353422Z",
     "start_time": "2019-09-13T09:46:04.098Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_final = test_pred_xgb.copy()\n",
    "sub_final['scalar_coupling_constant'] = test_pred_xgb['scalar_coupling_constant'] * 0.5 + test_pred_huber['scalar_coupling_constant'] * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:52:41.354216Z",
     "start_time": "2019-09-13T09:46:04.338Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_final = sub_final.drop(['index', 'molecule_name', 'atom_index_0', 'atom_index_1', 'type'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:52:41.355042Z",
     "start_time": "2019-09-13T09:46:04.714Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_final.to_csv('sub_stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:52:41.355914Z",
     "start_time": "2019-09-13T09:46:05.186Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv('sub_stacking.csv').shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
